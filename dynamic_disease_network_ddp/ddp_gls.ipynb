{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import data_loader\n",
    "import models\n",
    "import pandas as pd\n",
    "\n",
    "ncsr = pd.read_csv('../justage_vars_init.csv', index_col=0)\n",
    "pkl = open('../ncsr_for_ddp.pickle', \"rb\")\n",
    "dpp_data = {}\n",
    "dpp_data['ncsr'] = pickle.load(pkl)\n",
    "ddp_data = dpp_data\n",
    "pkl.close()\n",
    "\n",
    "max_len = max([len(ddp_data['ncsr'][x]) for  x in range(len(ddp_data['ncsr']))])\n",
    "n_event_type = dim_process = len(ncsr.columns) \n",
    "n_sample = len(ddp_data['ncsr'])\n",
    "context_dim = 1\n",
    "\n",
    "\n",
    "train_input = data_loader.process_seq(ddp_data, list(range(n_sample)), max_len=max_len, n_event_type=n_event_type, tag_batch = 'ncsr', dtype=np.float32)\n",
    "\n",
    "batch_input_np = list(train_input)\n",
    "df_patient_static_mat = np.ones((1, n_sample)).astype('float32')\n",
    "batch_input_np.append(df_patient_static_mat)\n",
    "\n",
    "\n",
    "gap = batch_input_np[0][:-1, :] - batch_input_np[0][1:, :]\n",
    "gap_mean = np.mean(gap)\n",
    "gap_std = np.std(gap)\n",
    "\n",
    "ddp_model = pickle.load(open('tst.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(ddp_data['ncsr'][x]) for  x in range(len(ddp_data['ncsr']))])\n",
    "n_event_type = dim_process = len(ncsr.columns) \n",
    "n_sample = len(ddp_data['ncsr'])\n",
    "context_dim = 1\n",
    "test_data = {}\n",
    "test_data['ncsr'] = []\n",
    "test_data['ncsr'].append(ddp_data['ncsr'][2][0:9])\n",
    "\n",
    "\n",
    "tst = data_loader.process_seq(test_data, list(range(1)), max_len=max_len, n_event_type=n_event_type, tag_batch = 'ncsr', dtype=np.float32)\n",
    "batch_input_np = list(tst)\n",
    "\n",
    "n_record = tst[0].shape[1]\n",
    "\n",
    "df_patient_static_mat = np.ones((1, n_sample)).astype('float32')\n",
    "batch_input_np.append(df_patient_static_mat)\n",
    "tst = batch_input_np\n",
    "idx = np.random.choice(list(range(n_record)), size=1, replace=False)\n",
    "mini_batch = list(map(lambda x: torch.tensor(x[..., idx]), tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "            ddp_model.set_input(*mini_batch)\n",
    "        \n",
    "            x = ddp_model.get_prediction()\n",
    "            y = ddp_model.next_event_time(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_output.append([y[0], y[1], [x[0] for x in y[2].tolist()]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ddp_model.get_prediction() dim: 309x126x2\n",
    "\n",
    "get_prediction:  symptom -> timepoint -> case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.1016]),\n",
       " tensor([219]),\n",
       " [0.0017784187803044915,\n",
       "  0.006235933862626553,\n",
       "  0.0026135004591196775,\n",
       "  0.006934584584087133,\n",
       "  0.0016796574927866459,\n",
       "  0.0017474814085289836,\n",
       "  0.0004928898997604847,\n",
       "  0.0017940286779776216,\n",
       "  0.0010215453803539276,\n",
       "  0.005255051422864199,\n",
       "  0.0020795834716409445,\n",
       "  0.0006186982500366867,\n",
       "  0.0007695105741731822,\n",
       "  0.0021040805149823427,\n",
       "  0.002127746120095253,\n",
       "  0.001978684216737747,\n",
       "  0.0014316182350739837,\n",
       "  0.0016522550722584128,\n",
       "  0.0022313487716019154,\n",
       "  0.0021269116550683975,\n",
       "  0.00200055749155581,\n",
       "  0.0011130566708743572,\n",
       "  0.002219418529421091,\n",
       "  0.0017088154563680291,\n",
       "  0.0017099367687478662,\n",
       "  0.002056656638160348,\n",
       "  0.0016049763653427362,\n",
       "  0.002009954769164324,\n",
       "  0.0023538183886557817,\n",
       "  0.0018740472150966525,\n",
       "  0.003752991557121277,\n",
       "  0.0025217270012944937,\n",
       "  0.0013435488799586892,\n",
       "  0.00411572027951479,\n",
       "  0.0035502964165061712,\n",
       "  0.002185362856835127,\n",
       "  0.002117177238687873,\n",
       "  0.0015056919073686004,\n",
       "  0.002742935437709093,\n",
       "  0.0016551099251955748,\n",
       "  0.0020171895157545805,\n",
       "  0.001797278644517064,\n",
       "  0.0011806903639808297,\n",
       "  0.00444959569722414,\n",
       "  0.0030742264352738857,\n",
       "  0.002287809271365404,\n",
       "  0.00046483511687256396,\n",
       "  0.0036225358489900827,\n",
       "  0.0030993735417723656,\n",
       "  0.00041089486330747604,\n",
       "  0.0015131626278162003,\n",
       "  0.0031313716899603605,\n",
       "  0.0017352073919028044,\n",
       "  0.00238142185844481,\n",
       "  0.0007430748664774001,\n",
       "  0.0032475998159497976,\n",
       "  0.002392934402450919,\n",
       "  0.0012970265233889222,\n",
       "  0.0019817498978227377,\n",
       "  0.002585779409855604,\n",
       "  0.0027014105580747128,\n",
       "  0.0019564612302929163,\n",
       "  0.0016840206226333976,\n",
       "  0.0023662743624299765,\n",
       "  0.0006797115784138441,\n",
       "  0.0011740208137780428,\n",
       "  0.0023135440424084663,\n",
       "  0.001236411277204752,\n",
       "  0.0018966185161843896,\n",
       "  0.0027039225678890944,\n",
       "  0.002111234702169895,\n",
       "  0.0020237972494214773,\n",
       "  0.00158945401199162,\n",
       "  0.001940268324688077,\n",
       "  0.00465809740126133,\n",
       "  0.003248845459893346,\n",
       "  0.0019604808185249567,\n",
       "  0.002795195672661066,\n",
       "  0.0009930592495948076,\n",
       "  0.0024817984085530043,\n",
       "  0.0031854959670454264,\n",
       "  0.0012481557205319405,\n",
       "  0.001939541776664555,\n",
       "  0.0020130884367972612,\n",
       "  0.0026771994307637215,\n",
       "  0.0032743255142122507,\n",
       "  0.0012272221501916647,\n",
       "  0.0024748514406383038,\n",
       "  0.0021803216077387333,\n",
       "  0.0025425797794014215,\n",
       "  0.0019567033741623163,\n",
       "  0.0022352945525199175,\n",
       "  0.0014139863196760416,\n",
       "  0.0021446687169373035,\n",
       "  0.0014872560277581215,\n",
       "  0.0022351513616740704,\n",
       "  0.002328898524865508,\n",
       "  0.0020709126256406307,\n",
       "  0.0012330003082752228,\n",
       "  0.0025452652480453253,\n",
       "  0.0021954949479550123,\n",
       "  0.010382763110101223,\n",
       "  0.008151248097419739,\n",
       "  0.004286556039005518,\n",
       "  0.0030306463595479727,\n",
       "  0.0054616788402199745,\n",
       "  0.004044559318572283,\n",
       "  0.0025260562542825937,\n",
       "  0.0034975712187588215,\n",
       "  0.0025434978306293488,\n",
       "  0.0004499819769989699,\n",
       "  0.0023761249613016844,\n",
       "  0.004793376196175814,\n",
       "  0.003939631395041943,\n",
       "  0.0014869383303448558,\n",
       "  0.002103429054841399,\n",
       "  0.0014750282280147076,\n",
       "  0.0010488764382898808,\n",
       "  0.0019432759145274758,\n",
       "  0.002015315694734454,\n",
       "  0.002364258747547865,\n",
       "  0.0019320925930514932,\n",
       "  0.000393958471249789,\n",
       "  0.0003102934279013425,\n",
       "  0.02036851830780506,\n",
       "  0.0008416277705691755,\n",
       "  0.002247460186481476,\n",
       "  0.0019361712038516998,\n",
       "  0.0025481185875833035,\n",
       "  0.001552131841890514,\n",
       "  0.011703258380293846,\n",
       "  0.0024564890190958977,\n",
       "  0.0036100419238209724,\n",
       "  0.001366843469440937,\n",
       "  0.0020261325407773256,\n",
       "  0.00212005153298378,\n",
       "  0.0026682750321924686,\n",
       "  0.002118693431839347,\n",
       "  0.0009923923062160611,\n",
       "  0.02542264387011528,\n",
       "  0.023908592760562897,\n",
       "  0.0010568362195044756,\n",
       "  0.0024969703517854214,\n",
       "  0.0022335753310471773,\n",
       "  0.0019362193997949362,\n",
       "  0.021372754126787186,\n",
       "  0.0021789311431348324,\n",
       "  0.002732026157900691,\n",
       "  0.001867489656433463,\n",
       "  0.004613466095179319,\n",
       "  0.006154524628072977,\n",
       "  0.004527711775153875,\n",
       "  0.0009981233160942793,\n",
       "  0.003053288673982024,\n",
       "  0.0003065330965910107,\n",
       "  0.002306672278791666,\n",
       "  0.0023417281918227673,\n",
       "  0.0037829112261533737,\n",
       "  0.002743195742368698,\n",
       "  0.0006203108350746334,\n",
       "  0.002495965687558055,\n",
       "  0.0023498614318668842,\n",
       "  0.0020215697586536407,\n",
       "  0.0023204958997666836,\n",
       "  0.0016242752317339182,\n",
       "  0.001986435614526272,\n",
       "  0.0012409498449414968,\n",
       "  0.0008627150673419237,\n",
       "  0.0016552542801946402,\n",
       "  0.00025171309243887663,\n",
       "  0.0012835919624194503,\n",
       "  0.0021732754539698362,\n",
       "  0.0021344441920518875,\n",
       "  0.0017153018852695823,\n",
       "  0.0003489515802357346,\n",
       "  0.0020041698589920998,\n",
       "  0.0019328062189742923,\n",
       "  0.0016806460916996002,\n",
       "  0.005276941228657961,\n",
       "  0.013014517724514008,\n",
       "  0.005662183742970228,\n",
       "  0.00535219581797719,\n",
       "  0.0024921230506151915,\n",
       "  0.001161778112873435,\n",
       "  0.0028725413139909506,\n",
       "  0.002031991956755519,\n",
       "  0.0017954716458916664,\n",
       "  0.0017420909134671092,\n",
       "  0.0013306126929819584,\n",
       "  0.0019315839745104313,\n",
       "  0.000571595854125917,\n",
       "  0.002017938531935215,\n",
       "  0.0016944885719567537,\n",
       "  0.001307716709561646,\n",
       "  0.0014425355475395918,\n",
       "  0.0012633070582523942,\n",
       "  0.0016848619561642408,\n",
       "  0.0020534652285277843,\n",
       "  0.0004261462017893791,\n",
       "  0.002498942194506526,\n",
       "  0.010122355073690414,\n",
       "  0.0011978271650150418,\n",
       "  0.001916903886012733,\n",
       "  0.0014106978196650743,\n",
       "  0.0020201937295496464,\n",
       "  0.0019967458210885525,\n",
       "  0.00197837152518332,\n",
       "  0.0014392184093594551,\n",
       "  0.002020691754296422,\n",
       "  0.0012400852283462882,\n",
       "  0.0015907429624348879,\n",
       "  0.002011658623814583,\n",
       "  0.0008508576429449022,\n",
       "  0.001743281609378755,\n",
       "  0.001952738268300891,\n",
       "  0.0014863059623166919,\n",
       "  0.002013063756749034,\n",
       "  0.0004985443083569407,\n",
       "  0.001837683143094182,\n",
       "  0.048492684960365295,\n",
       "  0.03943059593439102,\n",
       "  0.0022559764329344034,\n",
       "  0.0058875675313174725,\n",
       "  0.034940142184495926,\n",
       "  0.018491214141249657,\n",
       "  0.0022131288424134254,\n",
       "  0.0023662997409701347,\n",
       "  0.0018257525516673923,\n",
       "  0.001886648708023131,\n",
       "  0.00201274361461401,\n",
       "  0.0017103232676163316,\n",
       "  0.0015007669571787119,\n",
       "  0.0009878749260678887,\n",
       "  0.001442942419089377,\n",
       "  0.0013469872064888477,\n",
       "  0.0019514536252245307,\n",
       "  0.001955911982804537,\n",
       "  0.0018419927218928933,\n",
       "  0.0008656249265186489,\n",
       "  0.0019979216158390045,\n",
       "  0.0031082783825695515,\n",
       "  0.002141666365787387,\n",
       "  0.0018492157105356455,\n",
       "  0.0018526546191424131,\n",
       "  0.0027004294097423553,\n",
       "  0.0020403533708304167,\n",
       "  0.02210870571434498,\n",
       "  0.03104437328875065,\n",
       "  0.002027481095865369,\n",
       "  0.0013471458805724978,\n",
       "  0.0021376439835876226,\n",
       "  0.0018721193773671985,\n",
       "  0.0009898333810269833,\n",
       "  0.0013790958328172565,\n",
       "  0.0007378332666121423,\n",
       "  0.0019196579232811928,\n",
       "  0.0007695669191889465,\n",
       "  0.0019794569816440344,\n",
       "  0.0016043431824073195,\n",
       "  0.0020739210303872824,\n",
       "  0.0019076834432780743,\n",
       "  0.002199331531301141,\n",
       "  0.0029724829364567995,\n",
       "  0.0013435547007247806,\n",
       "  0.0020545616280287504,\n",
       "  0.0013235352234914899,\n",
       "  0.002351487521082163,\n",
       "  0.001997876912355423,\n",
       "  0.006225633900612593,\n",
       "  0.0028870664536952972,\n",
       "  0.0030043881852179766,\n",
       "  0.0014002103125676513,\n",
       "  0.0023098476231098175,\n",
       "  0.0018514677649363875,\n",
       "  0.0017252485267817974,\n",
       "  0.002250297926366329,\n",
       "  0.0015916040865704417,\n",
       "  0.0009182947687804699,\n",
       "  0.0027462979778647423,\n",
       "  0.0019228218588978052,\n",
       "  0.0009922048775479198,\n",
       "  0.001845651539042592,\n",
       "  0.0016408344963565469,\n",
       "  0.0020964837167412043,\n",
       "  0.02533837780356407,\n",
       "  0.015690622851252556,\n",
       "  0.002692807000130415,\n",
       "  0.01411369163542986,\n",
       "  0.0015055350959300995,\n",
       "  0.000852443219628185,\n",
       "  0.0017316568410024047,\n",
       "  0.0011983634904026985,\n",
       "  0.0017299818573519588,\n",
       "  0.0017823611851781607,\n",
       "  0.0009041756275109947,\n",
       "  0.0019435221329331398,\n",
       "  0.0023886719718575478,\n",
       "  0.0007884514052420855,\n",
       "  0.0019564495887607336,\n",
       "  0.0014043084811419249,\n",
       "  0.00041381671326234937,\n",
       "  0.0019072178984060884,\n",
       "  0.001992646837607026,\n",
       "  0.002104679588228464,\n",
       "  0.002099064877256751,\n",
       "  0.001600847695954144,\n",
       "  0.0020424332469701767,\n",
       "  0.0012582220369949937,\n",
       "  0.0017560272244736552]]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, x in enumerate(case_batch):\n",
    "    case_batch[idx][x!=0]  =  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_batch[8][0] = torch.Tensor([np.float32(1.0)]).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(case_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
